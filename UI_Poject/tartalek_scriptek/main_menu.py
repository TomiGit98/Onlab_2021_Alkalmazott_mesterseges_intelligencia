# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'main_menu.ui'
#
# Created by: PyQt5 UI code generator 5.15.4
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


from PyQt5 import QtCore, QtGui, QtWidgets

import face_landmark_detection
import detect_body_part_opencv
import age_and_gender
import facial_expressions_recognition
import recognize_face
import traind_model_to_recognize
import tensorflow_neural_network_person

import time

import speech_recognition as sr


class Ui_MainWindow(object):
    def setupUi(self, MainWindow):
        MainWindow.setObjectName("MainWindow")
        MainWindow.resize(760, 610)
        MainWindow.setStyleSheet("background-color: #252525")
        self.centralwidget = QtWidgets.QWidget(MainWindow)
        self.centralwidget.setObjectName("centralwidget")
        self.scaleFactorMinusButton = QtWidgets.QPushButton(self.centralwidget)
        self.scaleFactorMinusButton.setGeometry(QtCore.QRect(300, 480, 171, 51))
        self.scaleFactorMinusButton.setStyleSheet("QPushButton#scaleFactorMinusButton {\n"
"    background-color: red;\n"
"    border-style: ;outset\n"
"    border-width: 0px;\n"
"    border-radius: 10px;\n"
"    border-color: red;\n"
"    font: bold 18px;\n"
"    min-width: 2em;\n"
"    padding: 6px;\n"
"}")
        self.scaleFactorMinusButton.setIconSize(QtCore.QSize(40, 40))
        self.scaleFactorMinusButton.setObjectName("scaleFactorMinusButton")
        self.detectBodyPart = QtWidgets.QPushButton(self.centralwidget)
        self.detectBodyPart.setGeometry(QtCore.QRect(100, 100, 561, 41))
        self.detectBodyPart.setStyleSheet("QPushButton#detectBodyPart {\n"
"    background-color: #39FF14;\n"
"    border-style: ;outset\n"
"    border-width: 0px;\n"
"    border-radius: 10px;\n"
"    border-color: #39FF14;\n"
"    font: bold 14px;\n"
"    min-width: 2em;\n"
"    padding: 6px;\n"
"}")
        self.detectBodyPart.setObjectName("detectBodyPart")
        self.detectFaceCountures = QtWidgets.QPushButton(self.centralwidget)
        self.detectFaceCountures.setGeometry(QtCore.QRect(100, 150, 561, 41))
        self.detectFaceCountures.setStyleSheet("QPushButton#detectFaceCountures {\n"
"    background-color: #39FF14;\n"
"    border-style: ;outset\n"
"    border-width: 0px;\n"
"    border-radius: 10px;\n"
"    border-color: #39FF14;\n"
"    font: bold 14px;\n"
"    min-width: 2em;\n"
"    padding: 6px;\n"
"}")
        self.detectFaceCountures.setObjectName("detectFaceCountures")
        self.detectAgeAndGender = QtWidgets.QPushButton(self.centralwidget)
        self.detectAgeAndGender.setGeometry(QtCore.QRect(100, 200, 561, 41))
        self.detectAgeAndGender.setStyleSheet("QPushButton#detectAgeAndGender {\n"
"    background-color: #39FF14;\n"
"    border-style: ;outset\n"
"    border-width: 0px;\n"
"    border-radius: 10px;\n"
"    border-color: #39FF14;\n"
"    font: bold 14px;\n"
"    min-width: 2em;\n"
"    padding: 6px;\n"
"}")
        self.detectAgeAndGender.setObjectName("detectAgeAndGender")
        self.detectFacialExpression = QtWidgets.QPushButton(self.centralwidget)
        self.detectFacialExpression.setGeometry(QtCore.QRect(100, 250, 561, 41))
        self.detectFacialExpression.setStyleSheet("QPushButton#detectFacialExpression {\n"
"    background-color: #39FF14;\n"
"    border-style: ;outset\n"
"    border-width: 0px;\n"
"    border-radius: 10px;\n"
"    border-color: #39FF14;\n"
"    font: bold 14px;\n"
"    min-width: 2em;\n"
"    padding: 6px;\n"
"}")
        self.detectFacialExpression.setObjectName("detectFacialExpression")
        self.recognizeFace = QtWidgets.QPushButton(self.centralwidget)
        self.recognizeFace.setGeometry(QtCore.QRect(100, 300, 561, 41))
        self.recognizeFace.setStyleSheet("QPushButton#recognizeFace {\n"
"    background-color: #39FF14;\n"
"    border-style: ;outset\n"
"    border-width: 0px;\n"
"    border-radius: 10px;\n"
"    border-color: #39FF14;\n"
"    font: bold 14px;\n"
"    min-width: 2em;\n"
"    padding: 6px;\n"
"}")
        self.recognizeFace.setObjectName("recognizeFace")
        self.tensorflowRun = QtWidgets.QPushButton(self.centralwidget)
        self.tensorflowRun.setGeometry(QtCore.QRect(100, 400, 561, 41))
        self.tensorflowRun.setStyleSheet("QPushButton#tensorflowRun {\n"
"    background-color: #39FF14;\n"
"    border-style: ;outset\n"
"    border-width: 0px;\n"
"    border-radius: 10px;\n"
"    border-color: #39FF14;\n"
"    font: bold 14px;\n"
"    min-width: 2em;\n"
"    padding: 6px;\n"
"}")
        self.tensorflowRun.setObjectName("tensorflowRun")
        self.classification = QtWidgets.QPushButton(self.centralwidget)
        self.classification.setGeometry(QtCore.QRect(100, 350, 561, 41))
        self.classification.setStyleSheet("QPushButton#classification {\n"
"    background-color: #39FF14;\n"
"    border-style: ;outset\n"
"    border-width: 0px;\n"
"    border-radius: 10px;\n"
"    border-color: #39FF14;\n"
"    font: bold 14px;\n"
"    min-width: 2em;\n"
"    padding: 6px;\n"
"}")
        self.classification.setObjectName("classification")
        self.labelAnalyze = QtWidgets.QLabel(self.centralwidget)
        self.labelAnalyze.setGeometry(QtCore.QRect(110, 0, 541, 71))
        font = QtGui.QFont()
        font.setPointSize(28)
        self.labelAnalyze.setFont(font)
        self.labelAnalyze.setStyleSheet("QPushButton#label {\n"
"    background-color: #39FF14;\n"
"    border-style: ;outset\n"
"    border-width: 0px;\n"
"    border-radius: 10px;\n"
"    border-color: #39FF14;\n"
"    font: bold 14px;\n"
"    min-width: 2em;\n"
"    padding: 6px;\n"
"}")
        self.labelAnalyze.setFrameShape(QtWidgets.QFrame.NoFrame)
        self.labelAnalyze.setAlignment(QtCore.Qt.AlignCenter)
        self.labelAnalyze.setObjectName("labelAnalyze")
        MainWindow.setCentralWidget(self.centralwidget)
        self.menubar = QtWidgets.QMenuBar(MainWindow)
        self.menubar.setGeometry(QtCore.QRect(0, 0, 760, 26))
        self.menubar.setObjectName("menubar")
        MainWindow.setMenuBar(self.menubar)
        self.statusbar = QtWidgets.QStatusBar(MainWindow)
        self.statusbar.setObjectName("statusbar")
        MainWindow.setStatusBar(self.statusbar)

        #
        #self.backToMenuButton.clicked.click(self.bactToMainMenu)
        self.detectFaceCountures.clicked.connect(self.DetectLandmark)
        self.detectFaceCountures.clicked.connect(MainWindow.close)

        self.detectBodyPart.clicked.connect(self.DetectBodypart)
        self.detectBodyPart.clicked.connect(MainWindow.close)

        self.detectAgeAndGender.clicked.connect(self.DetectAgeAndGender)
        self.detectAgeAndGender.clicked.connect(MainWindow.close)

        self.detectFacialExpression.clicked.connect(self.DetectFacialExpression)
        self.detectFacialExpression.clicked.connect(MainWindow.close)

        self.recognizeFace.clicked.connect(self.RecogniseFace)
        self.recognizeFace.clicked.connect(MainWindow.close)

        self.classification.clicked.connect(self.Classification)
        self.classification.clicked.connect(MainWindow.close)

        self.tensorflowRun.clicked.connect(self.TensorflowPersonDetection)
        self.tensorflowRun.clicked.connect(MainWindow.close)

        self.scaleFactorMinusButton.clicked.connect(MainWindow.close)

        #
        self.startRecognizer()
        #

        self.retranslateUi(MainWindow)
        QtCore.QMetaObject.connectSlotsByName(MainWindow)

    def retranslateUi(self, MainWindow):
        _translate = QtCore.QCoreApplication.translate
        MainWindow.setWindowTitle(_translate("MainWindow", "MainWindow"))
        self.scaleFactorMinusButton.setText(_translate("MainWindow", "Quit"))
        self.detectBodyPart.setText(_translate("MainWindow", "Detect Body Part"))
        self.detectFaceCountures.setText(_translate("MainWindow", "Detect Face Counture"))
        self.detectAgeAndGender.setText(_translate("MainWindow", "Detect Age and Gender"))
        self.detectFacialExpression.setText(_translate("MainWindow", "Detect Facial Expression"))
        self.recognizeFace.setText(_translate("MainWindow", "Recognize Face"))
        self.tensorflowRun.setText(_translate("MainWindow", "Neural Network object detection"))
        self.classification.setText(_translate("MainWindow", "Classification"))
        self.labelAnalyze.setText(_translate("MainWindow", "Analysis"))


        self.labelAnalyze.setText("<font color='red'>Analysis</font>")


    def DetectLandmark(self):
        print("Landmark")
        self.window2 = QtWidgets.QMainWindow()
        self.ui = face_landmark_detection.Ui_MainWindow()
        self.ui.setupUi(self.window2)
        self.window2.show()


    def DetectBodypart(self):
        self.windowDetectBodyPart = QtWidgets.QMainWindow()
        self.ui = detect_body_part_opencv.Ui_MainWindow()
        self.ui.setupUi(self.windowDetectBodyPart)
        self.windowDetectBodyPart.show()


    def DetectAgeAndGender(self):
        self.windowAgeAndGender = QtWidgets.QMainWindow()
        self.ui = age_and_gender.Ui_MainWindow()
        self.ui.setupUi(self.windowAgeAndGender)
        self.windowAgeAndGender.show()

    def DetectFacialExpression(self):
        self.windowFacialExpression = QtWidgets.QMainWindow()
        self.ui = facial_expressions_recognition.Ui_MainWindow()
        self.ui.setupUi(self.windowFacialExpression)
        self.windowFacialExpression.show()

    def RecogniseFace(self):
        self.windowRecogniseFace = QtWidgets.QMainWindow()
        self.ui = recognize_face.Ui_MainWindow()
        self.ui.setupUi(self.windowRecogniseFace)
        self.windowRecogniseFace.show()

    def Classification(self):
        self.windowClassification = QtWidgets.QMainWindow()
        self.ui = traind_model_to_recognize.Ui_MainWindow()
        self.ui.setupUi(self.windowClassification)
        self.windowClassification.show()

    def TensorflowPersonDetection(self):
        self.windowTensorflowPersonDetection = QtWidgets.QMainWindow()
        self.ui = tensorflow_neural_network_person.Ui_MainWindow()
        self.ui.setupUi(self.windowTensorflowPersonDetection)
        self.windowTensorflowPersonDetection.show()


    def processSpeech(self, word):
        if word == "body" or word == "Body":
            self.detectBodyPart.click()
        elif "landmark" in word or "Landmark" in word:
            self.detectFaceCountures.click()
        elif "age" in word or "Age" in word or "gender" in word or "Gender" in word:
            self.detectAgeAndGender.click()
        elif "expression" in word or "Expression" in word:
            self.detectFacialExpression.click()
        elif "recognize" in word or "Recognize" in word or "recognise" in word or "Recognise" in word:
            self.recognizeFace.click()
        elif "classification" in word or "Classification" in word:
            self.classification.click()
        elif "tensorflow" in word or "person detection" in word:
            self.tensorflowRun.click()
        elif "exit" in word or "Exit" in word or "quit" in word or "Quit" in word:
            MainWindow.close()


    # this is called from the background thread
    def callback(self, recognizer, audio):
        # received audio data, now we'll recognize it using Google Speech Recognition
        try:
            # for testing purposes, we're just using the default API key
            # to use another API key, use `r.recognize_google(audio, key="GOOGLE_SPEECH_RECOGNITION_API_KEY")`
            # instead of `r.recognize_google(audio)`
            print("Google Speech Recognition thinks you said " + recognizer.recognize_google(audio))
            self.processSpeech(recognizer.recognize_google(audio))
            # self.backToMenuButton.click()
        except sr.UnknownValueError:
            print("Google Speech Recognition could not understand audio")
        except sr.RequestError as e:
            print("Could not request results from Google Speech Recognition service; {0}".format(e))

    def startRecognizer(self):
        print("Start Recognizer")
        r = sr.Recognizer()
        m = sr.Microphone()
        with m as source:
            r.adjust_for_ambient_noise(source)
        stop_listening = r.listen_in_background(m, self.callback)
        # stop_listening(wait_for_stop=False)
        # print("Stop Recognizer")




if __name__ == "__main__":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    MainWindow = QtWidgets.QMainWindow()
    ui = Ui_MainWindow()
    ui.setupUi(MainWindow)
    MainWindow.show()
    sys.exit(app.exec_())
