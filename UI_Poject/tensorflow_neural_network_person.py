# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'tensorflow_neural_network_person.ui'
#
# Created by: PyQt5 UI code generator 5.15.4
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.

import numpy as np
import tensorflow as tf

import pathlib

from object_detection.utils import ops as utils_ops
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as vis_util

utils_ops.tf = tf.compat.v1

tf.gfile = tf.io.gfile

from PyQt5 import QtCore, QtGui, QtWidgets, Qt
from PyQt5.QtGui import QPixmap
from PyQt5.QtWidgets import QFileDialog

import cv2 as cv

import main_menu

import speech_recognition as sr


# List of the strings that is used to add correct label for each box.
PATH_TO_LABELS = 'C:\\Users\\Tomi\\Desktop\\models-master\\research\\object_detection\\training\\labelmap.pbtxt'
category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)

PATH_TO_TEST_IMAGES_DIR = pathlib.Path('object_detection/test_images')
TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob("*.jpg")))

detection_model = tf.saved_model.load('C:\\Users\\Tomi\\Desktop\\models-master\\research\\object_detection\\new_graph\\saved_model')


class Ui_MainWindow(object):
    def setupUi(self, MainWindow):
        MainWindow.setObjectName("MainWindow")
        MainWindow.resize(760, 610)
        MainWindow.setStyleSheet("background-color: #252525")
        self.centralwidget = QtWidgets.QWidget(MainWindow)
        self.centralwidget.setObjectName("centralwidget")
        self.image = QtWidgets.QLabel(self.centralwidget)
        self.image.setGeometry(QtCore.QRect(19, 10, 731, 400))
        self.image.setAutoFillBackground(False)
        self.image.setText("")
        self.image.setObjectName("image")
        self.openButton = QtWidgets.QPushButton(self.centralwidget)
        self.openButton.setGeometry(QtCore.QRect(200, 420, 291, 131))
        self.openButton.setStyleSheet("QPushButton#openButton {\n"
"    background-color: #39FF14;\n"
"    border-style: ;outset\n"
"    border-width: 0px;\n"
"    border-radius: 10px;\n"
"    border-color: #39FF14;\n"
"    font: bold 14px;\n"
"    min-width: 2em;\n"
"    padding: 6px;\n"
"}")
        self.openButton.setObjectName("openButton")
        self.detectPersonFullBody = QtWidgets.QPushButton(self.centralwidget)
        self.detectPersonFullBody.setGeometry(QtCore.QRect(500, 420, 241, 131))
        self.detectPersonFullBody.setStyleSheet("QPushButton#detectPersonFullBody {\n"
"    background-color: red;\n"
"    border-style: ;outset\n"
"    border-width: 0px;\n"
"    border-radius: 10px;\n"
"    border-color: red;\n"
"    font: bold 18px;\n"
"    min-width: 2em;\n"
"    padding: 6px;\n"
"}")
        self.detectPersonFullBody.setIconSize(QtCore.QSize(40, 40))
        self.detectPersonFullBody.setObjectName("detectPersonFullBody")
        self.backToMenuButton = QtWidgets.QPushButton(self.centralwidget)
        self.backToMenuButton.setGeometry(QtCore.QRect(20, 420, 141, 131))
        self.backToMenuButton.setStyleSheet("QPushButton#backToMenuButton {\n"
"    background-color: #CBCBCB;\n"
"    border-style: ;outset\n"
"    border-width: 0px;\n"
"    border-radius: 10px;\n"
"    border-color: #39FF14;\n"
"    font: bold 14px;\n"
"    min-width: 2em;\n"
"    padding: 6px;\n"
"}")
        self.backToMenuButton.setIconSize(QtCore.QSize(40, 40))
        self.backToMenuButton.setObjectName("backToMenuButton")
        MainWindow.setCentralWidget(self.centralwidget)
        self.menubar = QtWidgets.QMenuBar(MainWindow)
        self.menubar.setGeometry(QtCore.QRect(0, 0, 760, 26))
        self.menubar.setObjectName("menubar")
        MainWindow.setMenuBar(self.menubar)
        self.statusbar = QtWidgets.QStatusBar(MainWindow)
        self.statusbar.setObjectName("statusbar")
        MainWindow.setStatusBar(self.statusbar)

        #
        self.openButton.clicked.connect(self.openFile)
        self.detectPersonFullBody.clicked.connect(self.detectPerson)

        self.backToMenuButton.clicked.connect(self.backToMainMenu)
        self.backToMenuButton.clicked.connect(MainWindow.close)

        self.startRecognizer()
        #

        self.retranslateUi(MainWindow)
        QtCore.QMetaObject.connectSlotsByName(MainWindow)

    def retranslateUi(self, MainWindow):
        _translate = QtCore.QCoreApplication.translate
        MainWindow.setWindowTitle(_translate("MainWindow", "MainWindow"))
        self.openButton.setText(_translate("MainWindow", "Open File"))
        self.detectPersonFullBody.setText(_translate("MainWindow", "Detect Person"))
        self.backToMenuButton.setText(_translate("MainWindow", "Back To Menu"))

    def run_inference_for_single_image(self, model, image):
        image = np.asarray(image)
        # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.
        input_tensor = tf.convert_to_tensor(image)
        # The model expects a batch of images, so add an axis with `tf.newaxis`.
        input_tensor = input_tensor[tf.newaxis, ...]

        # Run inference
        model_fn = model.signatures['serving_default']
        output_dict = model_fn(input_tensor)
        #   print(output_dict)
        # All outputs are batches tensors.
        # Convert to numpy arrays, and take index [0] to remove the batch dimension.
        # We're only interested in the first num_detections.
        num_detections = int(output_dict.pop('num_detections'))
        output_dict = {key: value[0, :num_detections].numpy()
                       for key, value in output_dict.items()}
        output_dict['num_detections'] = num_detections

        # detection_classes should be ints.
        output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)
        #   print(output_dict['detection_classes'])
        # Handle models with masks:
        if 'detection_masks' in output_dict:
            # Reframe the the bbox mask to the image size.
            detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(
                output_dict['detection_masks'], output_dict['detection_boxes'],
                image.shape[0], image.shape[1])
            detection_masks_reframed = tf.cast(detection_masks_reframed > 0.8,
                                               tf.uint8)
            output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()

        return output_dict

    def show_inference(self, model, image_np):
        # the array based representation of the image will be used later in order to prepare the
        # result image with boxes and labels on it.
        #   image_np = np.array(Image.open(image_path))
        # Actual detection.
        output_dict = self.run_inference_for_single_image(model, image_np)

        #   print(category_index)
        # Visualization of the results of a detection.
        final_img = vis_util.visualize_boxes_and_labels_on_image_array(
            image_np,
            output_dict['detection_boxes'],
            output_dict['detection_classes'],
            output_dict['detection_scores'],
            category_index,
            instance_masks=output_dict.get('detection_masks_reframed', None),
            use_normalized_coordinates=True,
            line_thickness=8)
        return (final_img)


    def detectPerson(self):
        cap = cv.VideoCapture(0)
        # img = cv.imread('C:\\Users\\Tomi\\Desktop\\models-master\\research\\object_detection\\person11.jpg')
        img = cv.imread(self.currentlyPresentedImageURL)

        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)
        final_img = self.show_inference(detection_model, img)

        final_img = cv.cvtColor(final_img, cv.COLOR_RGB2BGR)

        # cv.imshow('img', final_img)

        cv.imwrite('TensorflowDetection/fullbody.jpg', final_img)
        self.pixmax = QtGui.QPixmap('TensorflowDetection/fullbody.jpg')
        temp_w, temp_h = self.resizeImage(self.pixmax.width(), self.pixmax.height())
        self.pixmax = self.pixmax.scaled(temp_w.__int__(), temp_h.__int__())
        self.image.setAlignment(Qt.Qt.AlignCenter)
        self.image.setPixmap(self.pixmax)


        cv.waitKey(0)


    def openFile(self):
        print("Open File")
        file_name, _ = QFileDialog.getOpenFileName(None, 'Open Image File', r"D:\\Python_projects\\ONLABOR\\UI_Poject",
                                                   "Image files (*.jpg *.jpeg *.gif)")

        print(file_name)
        if(file_name != ""):
            self.currentlyPresentedImageURL = file_name
            print(self.currentlyPresentedImageURL)

            pixmap = QPixmap(file_name)
            temp_w = pixmap.width()
            temp_h = pixmap.height()
            print("width: " + str(temp_w))
            print("height: " + str(temp_h))
            temp_w, temp_h = self.resizeImage(pixmap.width(), pixmap.height())
            print("After resize")
            print("width: " + str(temp_w))
            print("height: " + str(temp_h))
            pixmap = pixmap.scaled(temp_w, temp_h)
            self.image.setPixmap(pixmap)
            print("Image width: " + str(self.image.width()))
            print("Image height: " + str(self.image.height()))
            self.image.setAlignment(Qt.Qt.AlignCenter)
        else:
            print("Nem nyitottál meg fájlt")

    def backToMainMenu(self):
        print("Back")
        self.window1 = QtWidgets.QMainWindow()
        self.ui = main_menu.Ui_MainWindow()
        self.ui.setupUi(self.window1)
        self.window1.show()

    def resizeImage(self, width, height):
        new_width, new_height, multiplier = 0, 0, 0
        if width > self.image.width() or height > self.image.height():
            for x in range(1000, 0, -1):
                new_width = width * (x / 1000)
                new_height = height * (x / 1000)
                if new_width <= self.image.width() and new_height <= self.image.height():
                    return new_width, new_height
        else:
            for x in range(1, 1000, 1):
                multiplier = 1 + (x / 100)
                new_width = width * multiplier
                new_height = height * multiplier
                print("width: " + str(new_width))
                print("height: " + str(new_height))
                if new_width > self.image.width() or new_height > self.image.height():
                    multiplier = 1 + ((x-1) / 100)
                    return width * multiplier, height * multiplier

    def processSpeech(self, word):
        if (word == "back" or word == "beck" or word == "Beck" or word == "Back"):
            self.backToMenuButton.click()
        elif "open" in word or "Open" in word:
            self.openButton.click()
        elif "detect" in word or "Detect" in word or "person" in word or "Person" in word:
            self.detectPersonFullBody.click()


    # this is called from the background thread
    def callback(self, recognizer, audio):
        # received audio data, now we'll recognize it using Google Speech Recognition
        try:
            # for testing purposes, we're just using the default API key
            # to use another API key, use `r.recognize_google(audio, key="GOOGLE_SPEECH_RECOGNITION_API_KEY")`
            # instead of `r.recognize_google(audio)`
            print("Google Speech Recognition thinks you said " + recognizer.recognize_google(audio))
            self.processSpeech(recognizer.recognize_google(audio))
            # self.backToMenuButton.click()
        except sr.UnknownValueError:
            print("Google Speech Recognition could not understand audio")
        except sr.RequestError as e:
            print("Could not request results from Google Speech Recognition service; {0}".format(e))

    def startRecognizer(self):
        print("Start Recognizer")
        r = sr.Recognizer()
        m = sr.Microphone()
        with m as source:
            r.adjust_for_ambient_noise(source)
        stop_listening = r.listen_in_background(m, self.callback)
        # stop_listening(wait_for_stop=False)
        # print("Stop Recognizer")


if __name__ == "__main__":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    MainWindow = QtWidgets.QMainWindow()
    ui = Ui_MainWindow()
    ui.setupUi(MainWindow)
    MainWindow.show()
    sys.exit(app.exec_())
