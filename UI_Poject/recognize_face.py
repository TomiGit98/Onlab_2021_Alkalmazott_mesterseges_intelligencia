# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'recognize_face.ui'
#
# Created by: PyQt5 UI code generator 5.15.2
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.
import os

import cv2
from PyQt5 import QtCore, QtGui, QtWidgets, Qt
from PyQt5.QtGui import QPixmap
from PyQt5.QtWidgets import QFileDialog

import main_menu

import speech_recognition as sr


class Ui_MainWindow(object):
    def setupUi(self, MainWindow):
        MainWindow.setObjectName("MainWindow")
        MainWindow.resize(658, 658)
        MainWindow.setStyleSheet("background-color: #252525")
        self.centralwidget = QtWidgets.QWidget(MainWindow)
        self.centralwidget.setObjectName("centralwidget")
        self.gridLayoutWidget = QtWidgets.QWidget(self.centralwidget)
        self.gridLayoutWidget.setGeometry(QtCore.QRect(10, 0, 641, 601))
        self.gridLayoutWidget.setMinimumSize(QtCore.QSize(641, 601))
        self.gridLayoutWidget.setObjectName("gridLayoutWidget")
        self.gridLayout_2 = QtWidgets.QGridLayout(self.gridLayoutWidget)
        self.gridLayout_2.setContentsMargins(0, 0, 0, 0)
        self.gridLayout_2.setVerticalSpacing(1)
        self.gridLayout_2.setObjectName("gridLayout_2")
        spacerItem = QtWidgets.QSpacerItem(20, 10, QtWidgets.QSizePolicy.Minimum, QtWidgets.QSizePolicy.Maximum)
        self.gridLayout_2.addItem(spacerItem, 3, 0, 1, 1)
        self.recognizeButton = QtWidgets.QPushButton(self.gridLayoutWidget)
        self.recognizeButton.setMinimumSize(QtCore.QSize(182, 0))
        self.recognizeButton.setStyleSheet("QPushButton#recognizeButton {\n"
"    background-color: red;\n"
"    border-style: ;outset\n"
"    border-width: 0px;\n"
"    border-radius: 10px;\n"
"    border-color: #39FF14;\n"
"    font: bold 14px;\n"
"    min-width: 10em;\n"
"    padding: 6px;\n"
"}")
        self.recognizeButton.setObjectName("recognizeButton")
        self.gridLayout_2.addWidget(self.recognizeButton, 1, 0, 1, 1, QtCore.Qt.AlignVCenter)
        self.backToMenuButton = QtWidgets.QPushButton(self.gridLayoutWidget)
        sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Minimum, QtWidgets.QSizePolicy.Expanding)
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(self.backToMenuButton.sizePolicy().hasHeightForWidth())
        self.backToMenuButton.setSizePolicy(sizePolicy)
        self.backToMenuButton.setStyleSheet("QPushButton#backToMenuButton {\n"
"    background-color: #CBCBCB;\n"
"    border-style: ;outset\n"
"    border-width: 0px;\n"
"    border-radius: 10px;\n"
"    border-color: #39FF14;\n"
"    font: bold 14px;\n"
"    min-width: 2em;\n"
"    padding: 6px;\n"
"}")
        self.backToMenuButton.setIconSize(QtCore.QSize(40, 40))
        self.backToMenuButton.setObjectName("backToMenuButton")
        self.gridLayout_2.addWidget(self.backToMenuButton, 4, 0, 1, 1, QtCore.Qt.AlignHCenter|QtCore.Qt.AlignBottom)
        self.openButton = QtWidgets.QPushButton(self.gridLayoutWidget)
        self.openButton.setStyleSheet("QPushButton#openButton {\n"
"    background-color: #39FF14;\n"
"    border-style: ;outset\n"
"    border-width: 0px;\n"
"    border-radius: 10px;\n"
"    border-color: #39FF14;\n"
"    font: bold 14px;\n"
"    min-width: 10em;\n"
"    padding: 6px;\n"
"}")
        self.openButton.setObjectName("openButton")
        self.gridLayout_2.addWidget(self.openButton, 2, 0, 1, 1)
        self.image = QtWidgets.QLabel(self.gridLayoutWidget)
        self.image.setText("")
        self.image.setObjectName("image")
        self.gridLayout_2.addWidget(self.image, 0, 0, 1, 1)
        self.gridLayout_2.setRowStretch(0, 7)
        MainWindow.setCentralWidget(self.centralwidget)
        self.menubar = QtWidgets.QMenuBar(MainWindow)
        self.menubar.setGeometry(QtCore.QRect(0, 0, 658, 26))
        self.menubar.setObjectName("menubar")
        MainWindow.setMenuBar(self.menubar)
        self.statusbar = QtWidgets.QStatusBar(MainWindow)
        self.statusbar.setObjectName("statusbar")
        MainWindow.setStatusBar(self.statusbar)

        #
        self.recognizeButton.clicked.connect(self.recognize)
        self.openButton.clicked.connect(self.openFile)

        self.backToMenuButton.clicked.connect(self.backToMainMenu)
        self.backToMenuButton.clicked.connect(MainWindow.close)
        #
        self.startRecognizer()
        #

        self.retranslateUi(MainWindow)
        QtCore.QMetaObject.connectSlotsByName(MainWindow)

    def retranslateUi(self, MainWindow):
        _translate = QtCore.QCoreApplication.translate
        MainWindow.setWindowTitle(_translate("MainWindow", "MainWindow"))
        self.recognizeButton.setText(_translate("MainWindow", "Recognize"))
        self.backToMenuButton.setText(_translate("MainWindow", "Back To Menu"))
        self.openButton.setText(_translate("MainWindow", "Open File"))


    def resizeImage(self, width, height):
        new_width, new_height, multiplier = 0, 0, 0
        if width > self.image.width() or height > self.image.height():
            for x in range(1000, 0, -1):
                new_width = width * (x / 1000)
                new_height = height * (x / 1000)
                if new_width <= self.image.width() and new_height <= self.image.height():
                    return new_width, new_height
        else:
            for x in range(1, 1000, 1):
                multiplier = 1 + (x / 100)
                new_width = width * multiplier
                new_height = height * multiplier
                print("width: " + str(new_width))
                print("height: " + str(new_height))
                if new_width > self.image.width() or new_height > self.image.height():
                    multiplier = 1 + ((x-1) / 100)
                    return width * multiplier, height * multiplier


    def openFile(self):
        print("Open File")
        file_name, _ = QFileDialog.getOpenFileName(None, 'Open Image File', r"D:\\Python_projects\\ONLABOR\\UI_Poject",
                                                   "Image files (*.jpg *.jpeg *.gif)")

        print(file_name)
        if (file_name != ""):
            self.currentlyPresentedImageURL = file_name
            print(self.currentlyPresentedImageURL)

            pixmap = QPixmap(file_name)
            temp_w = pixmap.width()
            temp_h = pixmap.height()
            print("width: " + str(temp_w))
            print("height: " + str(temp_h))
            temp_w, temp_h = self.resizeImage(pixmap.width(), pixmap.height())
            print("After resize")
            print("width: " + str(temp_w))
            print("height: " + str(temp_h))
            pixmap = pixmap.scaled(temp_w, temp_h)
            self.image.setPixmap(pixmap)
            print("Image width: " + str(self.image.width()))
            print("Image height: " + str(self.image.height()))
            self.image.setAlignment(Qt.Qt.AlignCenter)
        else:
            print("Nem nyitottál meg fájlt")

    def backToMainMenu(self):
        print("Back")
        self.window1 = QtWidgets.QMainWindow()
        self.ui = main_menu.Ui_MainWindow()
        self.ui.setupUi(self.window1)
        self.window1.show()

    def recognize(self):
        faceCascade = cv2.CascadeClassifier("HaarCascade/haar_frontalface.xml")
        # video_capture = cv2.VideoCapture(0)

        # Call the trained model yml file to recognize faces
        recognizer = cv2.face.LBPHFaceRecognizer_create()
        recognizer.read("training.yml")

        # Names corresponding to each id
        names = []
        for users in os.listdir("FaceRecognition\Datasets"):
            names.append(users)
            print(users)

        #img = cv2.imread("FaceRecognition\Test\{}".format("mark_chris.jpg"))
        img = cv2.imread(self.currentlyPresentedImageURL)

        gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        faces = faceCascade.detectMultiScale(
            gray_image, scaleFactor=1.2, minNeighbors=5, minSize=(100, 100)
        )

        # Try to predict the face and get the id
        # Then check if id == 1 or id == 2
        # Accordingly add the names
        for (x, y, w, h) in faces:
            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)
            id, confidence = recognizer.predict(gray_image[y: y + h, x: x + w])
            print("label=" + str(id) + " confidence=" + str(confidence))
            if id:
                cv2.putText(img, names[id - 1], (x, y - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 1, cv2.LINE_AA)
            else:
                cv2.putText(img, "Unknown", (x, y - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 1, cv2.LINE_AA)
            #cv2.imshow("Recognize", img)

            cv2.imwrite('FaceRecognition/temp/recognized.jpg', img)
            self.pixmax = QtGui.QPixmap('FaceRecognition/temp/recognized.jpg')
            temp_w, temp_h = self.resizeImage(self.pixmax.width(), self.pixmax.height())
            self.pixmax = self.pixmax.scaled(temp_w.__int__(), temp_h.__int__())
            self.image.setAlignment(Qt.Qt.AlignCenter)
            self.image.setPixmap(self.pixmax)

            cv2.waitKey(0)

            # if cv2.waitKey(1) & 0xFF == ord("q"):
            # break
        # cv2.destroyAllWindows()


    def processSpeech(self, word):
        if word == "back" or word == "beck" or word == "Beck" or word == "Back":
            self.backToMenuButton.click()
        elif "open" in word or "Open" in word:
            self.openFile()
        elif "face" in word or "Face" in word or "detect" in word or "Detect" in word \
                or "recognise" in word or "Recognise" in word:
            self.recognizeButton.click()


    # this is called from the background thread
    def callback(self, recognizer, audio):
        # received audio data, now we'll recognize it using Google Speech Recognition
        try:
            # for testing purposes, we're just using the default API key
            # to use another API key, use `r.recognize_google(audio, key="GOOGLE_SPEECH_RECOGNITION_API_KEY")`
            # instead of `r.recognize_google(audio)`
            print("Google Speech Recognition thinks you said " + recognizer.recognize_google(audio))
            self.processSpeech(recognizer.recognize_google(audio))
            # self.backToMenuButton.click()
        except sr.UnknownValueError:
            print("Google Speech Recognition could not understand audio")
        except sr.RequestError as e:
            print("Could not request results from Google Speech Recognition service; {0}".format(e))

    def startRecognizer(self):
        print("Start Recognizer")
        r = sr.Recognizer()
        m = sr.Microphone()
        with m as source:
            r.adjust_for_ambient_noise(source)
        stop_listening = r.listen_in_background(m, self.callback)
        # stop_listening(wait_for_stop=False)
        # print("Stop Recognizer")



if __name__ == "__main__":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    MainWindow = QtWidgets.QMainWindow()
    ui = Ui_MainWindow()
    ui.setupUi(MainWindow)
    MainWindow.show()
    sys.exit(app.exec_())
